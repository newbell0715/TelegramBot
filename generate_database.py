import json
import asyncio
import time
from services.gemini_service import call_gemini

async def generate_vocabulary_batch(start_id, count=100):
    """ë‹¨ì–´ ë°°ì¹˜ ìƒì„±"""
    prompt = f"""
    ì´ˆê¸‰ ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ {count}ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

    [
        {{
            "id": {start_id},
            "russian": "[ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´]",
            "korean": "[í•œêµ­ì–´ ëœ»]",
            "pronunciation": "[í•œê¸€ ë°œìŒ]",
            "level": "beginner",
            "category": "[ì¹´í…Œê³ ë¦¬]"
        }},
        ...
    ]

    ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ: greetings, family, food, colors, numbers, body, animals, weather, time, transportation, emotions, actions, objects, clothing, house, school, work, nature, health, sports

    - ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ëŸ¬ì‹œì•„ì–´ ë‹¨ì–´ë§Œ ì‚¬ìš©
    - ì´ˆê¸‰ìê°€ ê¼­ ì•Œì•„ì•¼ í•  ê¸°ë³¸ ë‹¨ì–´ë“¤
    - í•œê¸€ ë°œìŒì€ í•œêµ­ì¸ì´ ì½ê¸° ì‰½ê²Œ í‘œê¸°
    - ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
    - JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ìƒëµ

    IDëŠ” {start_id}ë¶€í„° {start_id + count - 1}ê¹Œì§€ ì—°ì†ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    
    result = await call_gemini(prompt)
    return result

async def generate_conversations_batch(start_id, count=50):
    """íšŒí™” ë¬¸ì¥ ë°°ì¹˜ ìƒì„±"""
    prompt = f"""
    ì´ˆê¸‰ ëŸ¬ì‹œì•„ì–´ íšŒí™” ë¬¸ì¥ {count}ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

    [
        {{
            "id": {start_id},
            "russian": "[ëŸ¬ì‹œì•„ì–´ ë¬¸ì¥]",
            "korean": "[í•œêµ­ì–´ ë²ˆì—­]",
            "pronunciation": "[í•œê¸€ ë°œìŒ]",
            "level": "beginner",
            "category": "[ì¹´í…Œê³ ë¦¬]"
        }},
        ...
    ]

    ì¹´í…Œê³ ë¦¬ ì˜ˆì‹œ: greetings, introductions, shopping, restaurant, directions, feelings, family, hobbies, weather, time, transportation, daily_life, apologizing, thanking, asking_help

    - ì‹¤ì œ ëŸ¬ì‹œì•„ì¸ì´ ìì£¼ ì‚¬ìš©í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥
    - ì´ˆê¸‰ìê°€ ì‹¤ìƒí™œì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í‘œí˜„
    - í•œê¸€ ë°œìŒì€ í•œêµ­ì¸ì´ ì½ê¸° ì‰½ê²Œ í‘œê¸°
    - ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
    - JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ ìƒëµ

    IDëŠ” {start_id}ë¶€í„° {start_id + count - 1}ê¹Œì§€ ì—°ì†ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    
    result = await call_gemini(prompt)
    return result

async def generate_full_database():
    """ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
    print("ğŸš€ ëŸ¬ì‹œì•„ì–´ í•™ìŠµ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì‹œì‘...")
    
    # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
    try:
        with open('russian_learning_database.json', 'r', encoding='utf-8') as f:
            database = json.load(f)
    except FileNotFoundError:
        database = {"vocabulary": [], "conversations": [], "metadata": {}}
    
    # ë‹¨ì–´ ìƒì„± (2000ê°œ)
    print("ğŸ“š ë‹¨ì–´ ìƒì„± ì¤‘...")
    vocabulary_batches = 20  # 100ê°œì”© 20ë²ˆ
    
    for i in range(vocabulary_batches):
        start_id = i * 100 + 1
        print(f"  ë°°ì¹˜ {i+1}/{vocabulary_batches}: ID {start_id}-{start_id+99}")
        
        try:
            batch_result = await generate_vocabulary_batch(start_id, 100)
            # JSON íŒŒì‹± ì‹œë„
            batch_data = json.loads(batch_result.strip())
            database["vocabulary"].extend(batch_data)
            
            # ì¤‘ê°„ ì €ì¥
            with open('russian_learning_database.json', 'w', encoding='utf-8') as f:
                json.dump(database, f, ensure_ascii=False, indent=2)
            
            print(f"    âœ… ì™„ë£Œ! í˜„ì¬ ë‹¨ì–´ ìˆ˜: {len(database['vocabulary'])}")
            
        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}")
            print(f"    ì‘ë‹µ: {batch_result[:200]}...")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
        await asyncio.sleep(2)
    
    # íšŒí™” ë¬¸ì¥ ìƒì„± (1000ê°œ)
    print("\nğŸ’¬ íšŒí™” ë¬¸ì¥ ìƒì„± ì¤‘...")
    conversation_batches = 20  # 50ê°œì”© 20ë²ˆ
    
    for i in range(conversation_batches):
        start_id = i * 50 + 1
        print(f"  ë°°ì¹˜ {i+1}/{conversation_batches}: ID {start_id}-{start_id+49}")
        
        try:
            batch_result = await generate_conversations_batch(start_id, 50)
            # JSON íŒŒì‹± ì‹œë„
            batch_data = json.loads(batch_result.strip())
            database["conversations"].extend(batch_data)
            
            # ì¤‘ê°„ ì €ì¥
            with open('russian_learning_database.json', 'w', encoding='utf-8') as f:
                json.dump(database, f, ensure_ascii=False, indent=2)
            
            print(f"    âœ… ì™„ë£Œ! í˜„ì¬ ë¬¸ì¥ ìˆ˜: {len(database['conversations'])}")
            
        except Exception as e:
            print(f"    âŒ ì˜¤ë¥˜: {e}")
            print(f"    ì‘ë‹µ: {batch_result[:200]}...")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
        await asyncio.sleep(2)
    
    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    database["metadata"] = {
        "last_updated": "2025-01-18",
        "total_vocabulary": len(database["vocabulary"]),
        "total_conversations": len(database["conversations"]),
        "target_vocabulary": 2000,
        "target_conversations": 1000
    }
    
    # ìµœì¢… ì €ì¥
    with open('russian_learning_database.json', 'w', encoding='utf-8') as f:
        json.dump(database, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ë‹¨ì–´: {len(database['vocabulary'])}ê°œ")
    print(f"ğŸ“Š ì´ íšŒí™”: {len(database['conversations'])}ê°œ")

if __name__ == "__main__":
    asyncio.run(generate_full_database()) 